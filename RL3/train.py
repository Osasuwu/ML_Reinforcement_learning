"""
Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸ pick-and-place.

Ð’Ñ…Ð¾Ð´: Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¸ÐºÑÐµÐ»Ð¸ (64x64 grayscale)
ÐœÐ¾Ð´ÐµÐ»ÑŒ: MobileNetV3-Small Ñ Ð·Ð°Ð¼Ð¾Ñ€Ð¾Ð·ÐºÐ¾Ð¹ ÑÐ»Ð¾Ñ‘Ð²
Ð¦ÐµÐ»ÑŒ: 1-2M ÑˆÐ°Ð³Ð¾Ð² Ð´Ð»Ñ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ ÑƒÑÐ¿ÐµÑ…Ð°
"""
import os
import json
import argparse
import numpy as np
import torch
from stable_baselines3 import PPO, SAC
from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv, VecMonitor
from stable_baselines3.common.callbacks import (
    CheckpointCallback, EvalCallback, CallbackList, BaseCallback
)
from stable_baselines3.common.monitor import Monitor

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ðº RL3 Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²
import sys
script_dir = os.path.dirname(os.path.abspath(__file__))
if script_dir not in sys.path:
    sys.path.insert(0, script_dir)

from robot_env import RobotEnv
from feature_extractor import MobileNetExtractor, EfficientNetExtractor, SimpleCNNExtractor


def parse_args():
    parser = argparse.ArgumentParser(description='Train pick-and-place robot')
    parser.add_argument('--steps', type=int, default=1_000_000,
                       help='Total timesteps (default: 1M)')
    parser.add_argument('--network', type=str, default='mobilenet',
                       choices=['mobilenet', 'efficientnet', 'cnn'],
                       help='Network architecture')
    parser.add_argument('--algo', type=str, default='ppo',
                       choices=['ppo', 'sac'],
                       help='RL algorithm')
    parser.add_argument('--camera', type=str, default='side',
                       choices=['side', 'wrist', 'both'],
                       help='Camera mode')
    parser.add_argument('--freeze', type=int, default=8,
                       help='Number of layers to freeze in pretrained model')
    parser.add_argument('--n_envs', type=int, default=4,
                       help='Number of parallel environments')
    parser.add_argument('--image_size', type=int, default=64,
                       help='Image size (64 recommended)')
    parser.add_argument('--eval_freq', type=int, default=25000,
                       help='Evaluation frequency')
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed')
    parser.add_argument('--render', type=int, default=2,
                       help='Episodes to render at each checkpoint (0 = disable)')
    return parser.parse_args()


class ProgressCallback(BaseCallback):
    """ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ Ð¸ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ"""
    def __init__(self, check_freq=10000, verbose=1):
        super().__init__(verbose)
        self.check_freq = check_freq
        self.best_success_rate = 0
        self.episode_successes = []
        
    def _on_step(self) -> bool:
        # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± ÑƒÑÐ¿ÐµÑ…Ð°Ñ…
        for info in self.locals.get('infos', []):
            if 'success' in info:
                self.episode_successes.append(info['success'])
        
        if self.n_calls % self.check_freq == 0 and len(self.model.ep_info_buffer) > 0:
            rewards = [ep['r'] for ep in self.model.ep_info_buffer]
            mean_reward = np.mean(rewards)
            
            # Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚ÑŒ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ ÑÐ¿Ð¸Ð·Ð¾Ð´Ñ‹
            recent_successes = self.episode_successes[-100:] if self.episode_successes else []
            success_rate = np.mean(recent_successes) * 100 if recent_successes else 0
            
            marker = ""
            if success_rate > self.best_success_rate:
                self.best_success_rate = success_rate
                marker = " ðŸŽ¯ NEW BEST!"
            
            print(f"\nStep {self.n_calls:,}: "
                  f"Mean R = {mean_reward:.2f}, "
                  f"Success = {success_rate:.1f}%{marker}")
        
        return True


class SuccessRateCallback(BaseCallback):
    """Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÑ‚ success rate Ð´Ð»Ñ TensorBoard"""
    def __init__(self, verbose=0):
        super().__init__(verbose)
        self.successes = []
        
    def _on_step(self) -> bool:
        for info in self.locals.get('infos', []):
            if 'success' in info:
                self.successes.append(float(info['success']))
        
        if len(self.successes) >= 100:
            success_rate = np.mean(self.successes[-100:])
            self.logger.record('rollout/success_rate', success_rate)
        
        return True


class PeriodicRenderCallback(BaseCallback):
    """
    ÐŸÐµÑ€Ð¸Ð¾Ð´Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ Ñ€ÐµÐ½Ð´ÐµÑ€-Ñ‚ÐµÑÑ‚.
    Checkpoints: ÐºÐ°Ð¶Ð´Ñ‹Ðµ 10k Ð´Ð¾ 100k, ÐºÐ°Ð¶Ð´Ñ‹Ðµ 50k Ð´Ð¾ 500k, ÐºÐ°Ð¶Ð´Ñ‹Ðµ 200k Ð¿Ð¾ÑÐ»Ðµ.
    """
    def __init__(self, models_dir, exp_name, env_kwargs, total_steps, 
                 render_episodes=2, verbose=1):
        super().__init__(verbose)
        self.models_dir = models_dir
        self.exp_name = exp_name
        self.env_kwargs = env_kwargs
        self.total_steps = total_steps
        self.render_episodes = render_episodes
        self.render_process = None
        
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº checkpoints Ð·Ð°Ñ€Ð°Ð½ÐµÐµ
        self.checkpoints = self._generate_checkpoints(total_steps)
        self.next_checkpoint_idx = 0
        
    def _generate_checkpoints(self, total_steps):
        """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº checkpoints"""
        checkpoints = []
        
        # ÐšÐ°Ð¶Ð´Ñ‹Ðµ 10k Ð´Ð¾ 100k
        for step in range(10000, min(100001, total_steps + 1), 10000):
            checkpoints.append(step)
        
        # ÐšÐ°Ð¶Ð´Ñ‹Ðµ 50k Ð¾Ñ‚ 100k Ð´Ð¾ 500k  
        for step in range(150000, min(500001, total_steps + 1), 50000):
            checkpoints.append(step)
        
        # ÐšÐ°Ð¶Ð´Ñ‹Ðµ 200k Ð¿Ð¾ÑÐ»Ðµ 500k
        for step in range(600000, total_steps + 1, 200000):
            checkpoints.append(step)
        
        return sorted(set(checkpoints))
    
    def _on_step(self) -> bool:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð»Ð¸ Ð»Ð¸ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ checkpoint
        if self.next_checkpoint_idx >= len(self.checkpoints):
            return True
            
        next_checkpoint = self.checkpoints[self.next_checkpoint_idx]
        
        if self.num_timesteps >= next_checkpoint:
            self.next_checkpoint_idx += 1
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ (Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ)
            save_path = os.path.abspath(os.path.join(
                self.models_dir, 
                f"{self.exp_name}_{next_checkpoint//1000}k.zip"
            ))
            self.model.save(save_path)
            
            if self.verbose:
                print(f"\n[CHECKPOINT {next_checkpoint//1000}k]")
                print(f"  Model saved: {save_path}")
                print(f"  Starting render test ({self.render_episodes} episodes)...")
            
            # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ñ€ÐµÐ½Ð´ÐµÑ€ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ
            self._start_render_test(save_path)
        
        return True
    
    def _start_render_test(self, model_path):
        """Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ Ñ‚ÐµÑÑ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ñ GUI Ð¾ÐºÐ½Ð¾Ð¼"""
        import subprocess
        import sys
        
        # Ð—Ð°Ð²ÐµÑ€ÑˆÐ°ÐµÐ¼ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ ÐµÑÐ»Ð¸ ÐµÑ‰Ñ‘ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
        if self.render_process is not None:
            try:
                self.render_process.terminate()
                self.render_process.wait(timeout=2)
            except:
                pass
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ðº test.py
        script_dir = os.path.dirname(os.path.abspath(__file__))
        test_script = os.path.join(script_dir, "test.py")
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ñ€ÐµÐ½Ð´ÐµÑ€Ð° Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¾ÐºÐ½Ðµ ÐºÐ¾Ð½ÑÐ¾Ð»Ð¸
        # start Ñ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð¼ Ð¾ÐºÐ½Ð° Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ ÐµÐ³Ð¾ Ð½Ð° Ð¿ÐµÑ€ÐµÐ´Ð½Ð¸Ð¹ Ð¿Ð»Ð°Ð½
        cmd = f'start "=== ROBOT RENDER TEST ===" cmd /c "python \\"{test_script}\\" \\"{model_path}\\" --episodes {self.render_episodes} --gui && pause"'
        
        try:
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ shell=True Ñ start Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð¾ÐºÐ½Ð°
            self.render_process = subprocess.Popen(
                cmd,
                shell=True
            )
            if self.verbose:
                print(f"  [OK] Render window opened")
        except Exception as e:
            if self.verbose:
                print(f"  [!] Failed to start render: {e}")
    
    def _on_training_end(self):
        """Ð–Ð´ÐµÐ¼ Ð¿Ð¾ÐºÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð·Ð°ÐºÑ€Ð¾ÐµÑ‚ Ð¾ÐºÐ½Ð¾ Ñ€ÐµÐ½Ð´ÐµÑ€Ð°"""
        if self.render_process is not None:
            try:
                # Ð–Ð´ÐµÐ¼ Ð¿Ð¾ÐºÐ° Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚ÑÑ (Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð·Ð°ÐºÑ€Ð¾ÐµÑ‚ Ð¾ÐºÐ½Ð¾)
                self.render_process.wait()
            except:
                pass


def make_env(rank, use_gui=False, **env_kwargs):
    def _init():
        env = RobotEnv(use_gui=use_gui, **env_kwargs)
        env = Monitor(env)
        return env
    return _init


def train(args):
    print("=" * 60)
    print("PICK-AND-PLACE ROBOT TRAINING")
    print("=" * 60)
    
    # Experiment name
    exp_name = f"pickplace_{args.network}_{args.camera}_{args.algo}_{args.steps//1000}k"
    
    # Directories (Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ RL3)
    rl3_dir = os.path.dirname(os.path.abspath(__file__))
    models_dir = os.path.join(rl3_dir, "models")
    logs_dir = os.path.join(rl3_dir, "logs", exp_name)
    tensorboard_dir = os.path.join(rl3_dir, "tensorboard", exp_name)
    
    os.makedirs(models_dir, exist_ok=True)
    os.makedirs(logs_dir, exist_ok=True)
    os.makedirs(tensorboard_dir, exist_ok=True)
    
    # Environment kwargs
    env_kwargs = {
        'image_size': args.image_size,
        'frame_stack': 4,
        'camera_mode': args.camera,
        'max_steps': 200
    }
    
    # Config
    config = {
        "experiment_name": exp_name,
        "network": args.network,
        "algorithm": args.algo,
        "camera_mode": args.camera,
        "image_size": args.image_size,
        "freeze_layers": args.freeze,
        "total_timesteps": args.steps,
        "n_envs": args.n_envs,
        "seed": args.seed
    }
    
    print(f"\nExperiment: {exp_name}")
    print(f"\nSettings:")
    print(f"  - Network: {args.network}")
    print(f"  - Algorithm: {args.algo}")
    print(f"  - Camera: {args.camera}")
    print(f"  - Image size: {args.image_size}x{args.image_size}")
    print(f"  - Freeze layers: {args.freeze}")
    print(f"  - Total steps: {args.steps:,}")
    print(f"  - Parallel envs: {args.n_envs}")
    if args.render > 0:
        print(f"  - Periodic render: {args.render} episodes at checkpoints")
    
    # Device
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"  - Device: {device}")
    if device == "cuda":
        print(f"    GPU: {torch.cuda.get_device_name(0)}")
    
    # Seeds
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    
    # Create environments
    print("\nCreating environments...")
    
    if args.n_envs > 1:
        env = SubprocVecEnv([make_env(i, use_gui=False, **env_kwargs) for i in range(args.n_envs)])
    else:
        env = DummyVecEnv([make_env(0, use_gui=False, **env_kwargs)])
    env = VecMonitor(env, logs_dir)
    
    eval_env = DummyVecEnv([make_env(0, use_gui=False, **env_kwargs)])
    eval_env = VecMonitor(eval_env, logs_dir)
    
    print("[OK] Environments created")
    
    # Select feature extractor
    if args.network == "mobilenet":
        extractor_class = MobileNetExtractor
        extractor_kwargs = {"features_dim": 256, "freeze_layers": args.freeze}
    elif args.network == "efficientnet":
        extractor_class = EfficientNetExtractor
        extractor_kwargs = {"features_dim": 256, "freeze_layers": args.freeze}
    else:
        extractor_class = SimpleCNNExtractor
        extractor_kwargs = {"features_dim": 256}
    
    policy_kwargs = dict(
        features_extractor_class=extractor_class,
        features_extractor_kwargs=extractor_kwargs,
        net_arch=dict(pi=[256, 128], vf=[256, 128])
    )
    
    # Create model
    print(f"\nCreating {args.algo.upper()} model...")
    
    if args.algo == "ppo":
        model = PPO(
            "CnnPolicy",
            env,
            policy_kwargs=policy_kwargs,
            learning_rate=3e-4,
            n_steps=2048,
            batch_size=256,
            n_epochs=10,
            gamma=0.99,
            gae_lambda=0.95,
            clip_range=0.2,
            ent_coef=0.01,
            max_grad_norm=0.5,
            verbose=1,
            tensorboard_log=tensorboard_dir,
            device=device,
            seed=args.seed
        )
    else:  # SAC
        model = SAC(
            "CnnPolicy",
            env,
            policy_kwargs=policy_kwargs,
            learning_rate=3e-4,
            buffer_size=100000,
            learning_starts=1000,
            batch_size=256,
            tau=0.005,
            gamma=0.99,
            train_freq=1,
            gradient_steps=1,
            verbose=1,
            tensorboard_log=tensorboard_dir,
            device=device,
            seed=args.seed
        )
    
    print("[OK] Model created")
    
    # Callbacks
    eval_cb = EvalCallback(
        eval_env,
        best_model_save_path=models_dir,
        log_path=logs_dir,
        eval_freq=args.eval_freq,
        n_eval_episodes=10,
        deterministic=True,
        render=False
    )
    
    progress_cb = ProgressCallback(check_freq=10000)
    success_cb = SuccessRateCallback()
    
    callbacks_list = [eval_cb, progress_cb, success_cb]
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ PeriodicRenderCallback ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶ÐµÐ½ Ñ€ÐµÐ½Ð´ÐµÑ€
    if args.render > 0:
        render_cb = PeriodicRenderCallback(
            models_dir=models_dir,
            exp_name=exp_name,
            env_kwargs=env_kwargs,
            total_steps=args.steps,
            render_episodes=args.render
        )
        callbacks_list.append(render_cb)
    
    callbacks = CallbackList(callbacks_list)
    
    # Training
    print("\n" + "=" * 60)
    print("STARTING TRAINING")
    if args.render > 0:
        print(f"  Periodic render: {args.render} episodes at checkpoints")
        print(f"  Save intervals: 10k -> 50k -> 200k steps")
    print("=" * 60)
    print(f"TensorBoard: tensorboard --logdir={tensorboard_dir}")
    print("=" * 60 + "\n")
    
    try:
        model.learn(
            total_timesteps=args.steps,
            callback=callbacks,
            progress_bar=True
        )
        
        # Save final model
        final_path = os.path.join(models_dir, f"{exp_name}_final.zip")
        model.save(final_path)
        
        # Save config
        config_path = final_path.replace('.zip', '_config.json')
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"\n[OK] Final model saved: {final_path}")
        
        # Rename best_model
        best_src = os.path.join(models_dir, "best_model.zip")
        best_dst = os.path.join(models_dir, f"{exp_name}_best.zip")
        if os.path.exists(best_src):
            if os.path.exists(best_dst):
                os.remove(best_dst)
            os.rename(best_src, best_dst)
            
            config_dst = best_dst.replace('.zip', '_config.json')
            with open(config_dst, 'w') as f:
                json.dump(config, f, indent=2)
            
            print(f"[OK] Best model saved: {best_dst}")
        
        print("\n" + "=" * 60)
        print("TRAINING COMPLETED!")
        print("=" * 60)
        
    except KeyboardInterrupt:
        print("\n[!] Training interrupted")
        interrupted_path = os.path.join(models_dir, f"{exp_name}_interrupted.zip")
        model.save(interrupted_path)
        print(f"[OK] Model saved: {interrupted_path}")
    
    finally:
        env.close()
        eval_env.close()


if __name__ == "__main__":
    args = parse_args()
    train(args)
